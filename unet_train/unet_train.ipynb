{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Replaced by more flexible logic below\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True' # Kept as per your original setup\n",
    "\n",
    "# --- GPU Configuration ---\n",
    "SPECIFIC_GPU_INDEX = 1  # <<< YOU CAN CHANGE THIS GPU INDEX (e.g., 0, 1, 2, ...)\n",
    "SELECTED_DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    if SPECIFIC_GPU_INDEX < torch.cuda.device_count():\n",
    "        SELECTED_DEVICE = torch.device(f'cuda:{SPECIFIC_GPU_INDEX}')\n",
    "        print(f\"Attempting to use CUDA device: cuda:{SPECIFIC_GPU_INDEX}\")\n",
    "    else:\n",
    "        print(f\"Warning: GPU index {SPECIFIC_GPU_INDEX} is out of range (0-{torch.cuda.device_count()-1}).\")\n",
    "        # Fallback logic: try cuda:0, then CPU\n",
    "        if torch.cuda.device_count() > 0:\n",
    "            SELECTED_DEVICE = torch.device('cuda:0')\n",
    "            print(\"Falling back to GPU 0 (cuda:0).\")\n",
    "        else:\n",
    "            SELECTED_DEVICE = torch.device('cpu')\n",
    "            print(\"No GPUs available. Falling back to CPU.\")\n",
    "else:\n",
    "    SELECTED_DEVICE = torch.device('cpu')\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "print(f\"Selected device: {SELECTED_DEVICE}\")\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    \"version_name\": \"v1-100epoch-lr1e-3-batch4-18may-13h-21m\", # Example, keep your versioning\n",
    "    \"log_base_dir\": Path(\"experiments\"), # This will be experiments within unet_train/\n",
    "    \"img_size\": 256,\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 2,\n",
    "    \"lr\": 1e-3,\n",
    "    \"bce_weight\": 0.5,\n",
    "    \"num_epochs\": 100,\n",
    "    \"device\": SELECTED_DEVICE, # Use the dynamically selected device\n",
    "    # data_root should point from unet_train/unet_train.ipynb to glomeruli_segmentation/datasets/\n",
    "    \"data_root\": Path(\"../datasets\"), # Relative path from unet_train/ to datasets/\n",
    "}\n",
    "\n",
    "# Verify paths (optional, for debugging)\n",
    "print(f\"Data root resolved to: {CONFIG['data_root'].resolve()}\")\n",
    "print(f\"Log base directory: {CONFIG['log_base_dir'].resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30993b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlomeruliDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.filenames = sorted(os.listdir(image_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        image = np.array(Image.open(self.image_dir / img_name).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_dir / img_name).convert(\"L\"))\n",
    "        mask = (mask != 0).astype(\"float32\")\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"].unsqueeze(0)\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(img_size):\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ElasticTransform(alpha=1, sigma=50, p=0.5),  # fixed: removed alpha_affine\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    return train_transform, val_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super().__init__()\n",
    "        def conv_block(ic, oc):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(ic, oc, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(oc, oc, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.enc5 = conv_block(512, 1024)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "        self.drop = nn.Dropout2d(0.5)\n",
    "        self.bottleneck = conv_block(1024, 2048)\n",
    "        self.up5 = nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2)\n",
    "        self.dec5 = conv_block(2048, 1024)\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = conv_block(1024, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        e4 = self.enc4(self.pool3(e3))\n",
    "        e5 = self.enc5(self.pool4(e4))\n",
    "        b = self.drop(self.bottleneck(self.pool5(e5)))\n",
    "        d5 = self.dec5(torch.cat([self.up5(b), e5], dim=1))\n",
    "        d4 = self.dec4(torch.cat([self.up4(d5), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        return self.final(d1)\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, smooth=1e-7):\n",
    "        super().__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        bce = self.bce(pred, target)\n",
    "        prob = torch.sigmoid(pred)\n",
    "        inter = (prob * target).sum(dim=(1, 2, 3))\n",
    "        union = prob.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3))\n",
    "        dice_loss = 1 - ((2 * inter + self.smooth) / (union + self.smooth)).mean()\n",
    "        return self.bce_weight * bce + (1 - self.bce_weight) * dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    cfg = CONFIG\n",
    "    version_dir = cfg[\"log_base_dir\"] / cfg[\"version_name\"]\n",
    "    log_dir = version_dir / \"logs\"\n",
    "    checkpoint_path = version_dir / \"best_model.pth\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    os.makedirs(version_dir, exist_ok=True)\n",
    "\n",
    "    train_tf, val_tf = get_transforms(cfg[\"img_size\"])\n",
    "    \n",
    "    # Updated dataset paths\n",
    "    train_ds = GlomeruliDataset(\n",
    "        cfg[\"data_root\"] / \"train\" / \"images\", \n",
    "        cfg[\"data_root\"] / \"train\" / \"masks\", \n",
    "        transform=train_tf\n",
    "    )\n",
    "    val_ds   = GlomeruliDataset(\n",
    "        cfg[\"data_root\"] / \"val\" / \"images\",   \n",
    "        cfg[\"data_root\"] / \"val\" / \"masks\", \n",
    "        transform=val_tf\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,  num_workers=cfg[\"num_workers\"])\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=cfg[\"batch_size\"], shuffle=False, num_workers=cfg[\"num_workers\"])\n",
    "\n",
    "    model = UNet().to(cfg[\"device\"])\n",
    "    criterion = BCEDiceLoss(cfg[\"bce_weight\"])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=str(log_dir))\n",
    "    best_dice = 0\n",
    "\n",
    "    for epoch in range(cfg[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Wrap train_loader with tqdm for a progress bar\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg['num_epochs']} [TRAIN]\", leave=False)\n",
    "        for images, masks in train_pbar:\n",
    "            images, masks = images.to(cfg[\"device\"]), masks.to(cfg[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        dice_all, iou_all = [], []\n",
    "        # Wrap val_loader with tqdm for a progress bar\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{cfg['num_epochs']} [VAL]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for i, (images, masks) in enumerate(val_pbar):\n",
    "                images, masks = images.to(cfg[\"device\"]), masks.to(cfg[\"device\"])\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                intersection = (pred_bin * masks).sum(dim=(1, 2, 3)) # Keep batch dimension for mean\n",
    "                # union for IoU\n",
    "                union_iou = pred_bin.sum(dim=(1, 2, 3)) + masks.sum(dim=(1, 2, 3)) - intersection\n",
    "                # sum for Dice\n",
    "                sum_dice = pred_bin.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3))\n",
    "\n",
    "                dice = (2. * intersection + 1e-7) / (sum_dice + 1e-7)\n",
    "                iou = (intersection + 1e-7) / (union_iou + 1e-7)\n",
    "                \n",
    "                dice_all.append(dice.mean().item()) # Append mean dice for the batch\n",
    "                iou_all.append(iou.mean().item())   # Append mean iou for the batch\n",
    "                val_pbar.set_postfix(loss=loss.item(), dice=dice.mean().item())\n",
    "\n",
    "                if i == 0: # Log first batch of validation images\n",
    "                    writer.add_image(\"val/image\", torchvision.utils.make_grid(images), epoch)\n",
    "                    writer.add_image(\"val/mask\", torchvision.utils.make_grid(masks), epoch)\n",
    "                    writer.add_image(\"val/prediction\", torchvision.utils.make_grid(pred_bin), epoch) # Log binary prediction for clarity\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_dice = np.mean(dice_all) # More robust way to calculate mean\n",
    "        avg_iou  = np.mean(iou_all)  # More robust way to calculate mean\n",
    "        \n",
    "        writer.add_scalar(\"Loss/val\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"Dice/val\", avg_dice, epoch)\n",
    "        writer.add_scalar(\"IoU/val\", avg_iou, epoch)\n",
    "        scheduler.step(avg_dice)\n",
    "\n",
    "        if avg_dice > best_dice:\n",
    "            best_dice = avg_dice\n",
    "            # Save to a temporary file first, then replace, to avoid corrupted file if process is interrupted\n",
    "            temp_checkpoint_path = str(checkpoint_path) + \".tmp\"\n",
    "            torch.save(model.state_dict(), temp_checkpoint_path)\n",
    "            os.replace(temp_checkpoint_path, checkpoint_path)\n",
    "            print(f\"Saved new best model with Dice {avg_dice:.4f}\") # Emoji removed\n",
    "\n",
    "        print(f\"[{epoch+1}/{cfg['num_epochs']}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f}\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training finished.\") # Added a finish message\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    cfg = CONFIG\n",
    "\n",
    "    # === Define paths based on version ===\n",
    "    version_dir = cfg[\"log_base_dir\"] / cfg[\"version_name\"]\n",
    "    checkpoint_path = version_dir / \"best_model.pth\"\n",
    "    # Ensure log_dir is defined for test phase if you intend to write separate test logs\n",
    "    # If reusing training logs, this might not be needed or could point to the same log_dir\n",
    "    test_log_dir = version_dir / \"logs_test\" # Or version_dir / \"logs\" to append\n",
    "    os.makedirs(test_log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # === Load test set ===\n",
    "    # Assuming get_transforms returns (train_transform, val_transform)\n",
    "    # Using [1] for val_transform as test_transform is good practice\n",
    "    _, test_transform = get_transforms(cfg[\"img_size\"]) # Get train and val, use val for test\n",
    "    \n",
    "    # Updated dataset path\n",
    "    test_ds = GlomeruliDataset(\n",
    "        cfg[\"data_root\"] / \"test\" / \"images\",\n",
    "        cfg[\"data_root\"] / \"test\" / \"masks\",\n",
    "        transform=test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=cfg[\"num_workers\"]) # Added num_workers\n",
    "\n",
    "    # === Load best model ===\n",
    "    model = UNet().to(cfg[\"device\"])\n",
    "    if not checkpoint_path.exists():\n",
    "        print(f\"Error: Model checkpoint not found at {checkpoint_path}\")\n",
    "        return\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=cfg[\"device\"]))\n",
    "    model.eval()\n",
    "\n",
    "    # === TensorBoard Writer ===\n",
    "    writer = SummaryWriter(log_dir=str(test_log_dir)) # Use test_log_dir\n",
    "    dice_scores, iou_scores = [], []\n",
    "\n",
    "    # Wrap test_loader with tqdm for a progress bar\n",
    "    test_pbar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for i, (image, mask) in enumerate(test_pbar): # Changed from image, mask in test_loader\n",
    "            image, mask = image.to(cfg[\"device\"]), mask.to(cfg[\"device\"])\n",
    "            pred = model(image)\n",
    "            pred_bin = (torch.sigmoid(pred) > 0.5).float()\n",
    "\n",
    "            # Calculations are per image since batch_size=1 for test_loader\n",
    "            intersection = (pred_bin * mask).sum() # sum over all (C, H, W) dims\n",
    "            # union for IoU\n",
    "            union_iou = pred_bin.sum() + mask.sum() - intersection\n",
    "            # sum for Dice\n",
    "            sum_dice = pred_bin.sum() + mask.sum()\n",
    "\n",
    "            dice = (2. * intersection + 1e-7) / (sum_dice + 1e-7)\n",
    "            iou = (intersection + 1e-7) / (union_iou + 1e-7)\n",
    "\n",
    "            dice_scores.append(dice.item())\n",
    "            iou_scores.append(iou.item())\n",
    "            test_pbar.set_postfix(dice=dice.item(), iou=iou.item())\n",
    "\n",
    "            # Optionally log some test images and predictions\n",
    "            if i < 5 : # Log first 5 test images/masks/predictions\n",
    "                writer.add_image(f\"test/image_{i}\", image.squeeze(0), global_step=0) # Squeeze batch dim\n",
    "                writer.add_image(f\"test/mask_{i}\", mask.squeeze(0), global_step=0)\n",
    "                writer.add_image(f\"test/prediction_{i}\", pred_bin.squeeze(0), global_step=0)\n",
    "\n",
    "\n",
    "    if not dice_scores: # Handle case where test set might be empty\n",
    "        print(\"Warning: No data in test set or dice_scores list is empty.\")\n",
    "        mean_dice = 0.0\n",
    "        mean_iou = 0.0\n",
    "    else:\n",
    "        mean_dice = np.mean(dice_scores)\n",
    "        mean_iou = np.mean(iou_scores)\n",
    "\n",
    "    print(f\"Test Dice: {mean_dice:.4f} | Test IoU: {mean_iou:.4f}\")\n",
    "    writer.add_scalar(\"Test/Dice_Overall\", mean_dice, global_step=0) # Use a distinct name or step\n",
    "    writer.add_scalar(\"Test/IoU_Overall\", mean_iou, global_step=0)\n",
    "    writer.close()\n",
    "    print(\"Testing finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Decide whether to run train or test, or both sequentially\n",
    "    # For now, assuming you might call them separately or have a different trigger\n",
    "    # If you run this script directly, it will attempt to call test() if this block is active\n",
    "    # train() # Uncomment to run training\n",
    "    test()  # Uncomment to run testing after potential training, or standalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828a62d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
